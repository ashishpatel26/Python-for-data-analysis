{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Primer - 3\n",
    "- Importing datasets\n",
    "    - loadtxt\n",
    "    - genfromtxt\n",
    "- Processing data\n",
    "    - Splitting data\n",
    "- Summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Datasets\n",
    "- Datasets in text files (```.txt, .csv```, etc.) can be imported using ```loadtxt()``` for ```genfromtxt()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loadtxt()\n",
    "- ```loadtxt()``` is used when there do not exist missing values\n",
    "- Hence, number of values in each row should be equal\n",
    "- Key parameters\n",
    "    - ```fname```: designates name of text file to be imported\n",
    "    - ```dtype```: data type of array to be created as result (default: ```float```)\n",
    "    - ```delimiter```: string used to separate values (default: whitespace)\n",
    "    - ```skiprows```: skip first *n* rows (default: 0)\n",
    "    - ```usecols```: column indices to be read (default: ```None``` => all cols are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing dataset with default settings\n",
    "data = np.loadtxt('even_numbers.txt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing dataset with parameter settings\n",
    "# skiprows is especially useful when you want to get rid of \"header\" of dataset \n",
    "data = np.loadtxt('even_numbers.txt', dtype = int, skiprows = 1, usecols = (1,3))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing dataset with parameter settings\n",
    "data = np.loadtxt('even_numbers.txt', dtype = np.str_, usecols = 0)\n",
    "print(data)        # note that resulting array is 1-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .csv files could be imported as well\n",
    "# in this case, delimiter should be set to ','\n",
    "data = np.loadtxt('glass.csv', delimiter = ',')\n",
    "print(data.shape)        # dataset with 214 rows & 11 columns\n",
    "print(data.dtype)        # dtype is float64 as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### genfromtxt()\n",
    "- ```genfromtxt()``` is used when dataset has some missing values\n",
    "- Otherwise, it is largely identical to ```loadtxt()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when ' '(whitespace) is used as delimiter\n",
    "data = np.genfromtxt('odd_numbers.txt', invalid_raise = False)\n",
    "print(data)      # you can see that last row is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when ',' is used as delimiter\n",
    "data = np.genfromtxt('odd_numbers.csv', delimiter = ',')\n",
    "print(data)      # you could see that last element is set to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# value to fill missing element can be deisgnated\n",
    "data = np.genfromtxt('odd_numbers.csv', delimiter = ',', filling_values = 100)\n",
    "print(data)       # fill missing value with 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if there is certain string to designate missing value ('?' here)\n",
    "data = np.genfromtxt('odd_numbers_2.csv', delimiter = ',', missing_values = '?', filling_values = 99)\n",
    "print(data)       # fill missing value with 99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-1.\n",
    "- Import ```highway.csv``` using genfromtxt()\n",
    "    - Set ```dtype``` as string\n",
    "    - Replace missing values (```'?'```) with ```'Unknown'```\n",
    "    - Print first three rows of resulting array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your answer\n",
    "data = np.genfromtxt('highway.csv', dtype = np.str_, delimiter = ',')\n",
    "data[data == '?'] = 'Unknown'   # use boolean indexing \n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing data\n",
    "- Processing imported dataset is essential task in data mining\n",
    "- Many techniques we have learnt so far are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data\n",
    "- In most cases, dataset is splitted into ```X data``` (input variables) and ```Y data``` (output variables), or other variable splits\n",
    "    - Then, dataset is splitted *column-wise*\n",
    "- Then, dataset is splitted into ```training data``` and ```validation/test data```, or cross-validated\n",
    "    - Then, dataset is splitted *row-wise*\n",
    "- In either case, array indexing & slicing are utilized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**glass dataset**\n",
    "- source: https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.names\n",
    "- Number of instances (# rows): 214\n",
    "- Number of attributes (# columns): 10\n",
    "    - ID number: 1 to 214\n",
    "    - RI: refractive index\n",
    "    - Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "    - Mg: Magnesium\n",
    "    - Al: Aluminum\n",
    "    - Si: Silicon\n",
    "    - K: Potassium\n",
    "    - Ca: Calcium\n",
    "    - Ba: Barium\n",
    "    - Fe: Iron\n",
    "    - Type of glass: (class attribute)\n",
    "        - 1: building_windows_float_processed\n",
    "        - 2: building_windows_non_float_processed\n",
    "        - 3: vehicle_windows_float_processed\n",
    "        - 4: vehicle_windows_non_float_processed (none in this database)\n",
    "        - 5: containers\n",
    "        - 6: tableware\n",
    "        - 7: headlamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dataset\n",
    "data = np.loadtxt('glass.csv', delimiter = ',')\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# excluding ID number variable\n",
    "data_1 = data[:, 1:]\n",
    "print(data_1.shape)        # 10 columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting only X data (excluding ID number & Type of glass variables)\n",
    "X_data = data[:, 1:-1]\n",
    "print(X_data.shape)        # 9 columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting only RI, Na, Mg variables\n",
    "X_partial = data[:, 1:4]\n",
    "print(X_partial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting only Y data\n",
    "Y_data = data[:, -1]\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting data into train-test set\n",
    "# first 150 data instances into train set, others into test set\n",
    "X_train = X_data[:150,:]\n",
    "X_test = X_data[150:, :]\n",
    "Y_train = Y_data[:150]\n",
    "Y_test = Y_data[150:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly performing train-test split\n",
    "data_shulffled = data               # copy data\n",
    "np.random.shuffle(data_shulffled)   # shulffle dataset randomly\n",
    "\n",
    "X_data = data_shulffled[:, 1:-1]\n",
    "Y_data = data_shulffled[:, -1]\n",
    "\n",
    "X_train = X_data[:150,:]\n",
    "X_test = X_data[150:, :]\n",
    "Y_train = Y_data[:150]\n",
    "Y_test = Y_data[150:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3-2.\n",
    "- Import ```dermatology.csv``` using ```genfromtxt()``` function\n",
    "    - Replace missing values ('?') with 0\n",
    "- Assign data in first 34 columns into X_data\n",
    "- Assign data in last column into Y_data\n",
    "- Perform train-test split\n",
    "    - Randomly assign half into train set, another half into test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer\n",
    "data = np.genfromtxt('dermatology.csv', delimiter = ',', missing_values = '?', filling_values = 0)\n",
    "#print(data.shape)\n",
    "\n",
    "train_len = len(data)//2\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X_train = data[:train_len, :-1]\n",
    "X_test = data[train_len:, :-1]\n",
    "y_train = data[:train_len, -1]\n",
    "y_test = data[train_len:, -1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
